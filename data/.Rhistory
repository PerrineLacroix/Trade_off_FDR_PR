n = 1708
p= 1943
2*n*log(n/p)
k = seq(1,n,by=100)
k
k = seq(1,n,by=10)
k
plot(k,2*k*log(k/p))
n
plot(k,2*k*log(p/k))
n
k = seq(1,p,by=10)
plot(k,2*k*log(p/k))
load("~/Documents/Encadrement_projet_Armand_Marion/Codes_utilises_pour_Review/Save_OLD/Save150/resultat_glm_knockoffs_150_200_100_scale-free_max_of_neighbour_threshold_accepte_0.8_randomized_1_lasso_1it_63.RData")
resultat_knockoffs
load("~/Documents/Encadrement_projet_Armand_Marion/Codes_utilises_pour_Review/Save_OLD/Save150/resultat_glm_knockoffs_150_200_100_scale-free_max_of_neighbour_threshold_accepte_0.8_randomized_1_lasso_1it_7.RData")
resultat_knockoffs[[2]]$TP
load("~/Documents/Encadrement_projet_Armand_Marion/Codes_utilises_pour_Review/Save_OLD/Save150/resultat_glm_Tigress_150_200_100_scale-free_max_of_neighbour_threshold_accepte_0.8_randomized_1_lasso_1it_95.RData")
resultat_TIGRESS[[2]]$TP
resultat_TIGRESS[[2]]$FP
rm(list=objects())
p=seq(1,4,by = 10)
p
p=seq(1,4,length.out = 10)
p
rnorm(n,mean = 0,sd = 1)
n=100
nbr_it = 1000
nbr_it = 1000
rnorm(n,mean = 0,sd = 1)
hist(rnorm(n,mean = 0,sd = 1))
hist(rnorm(n,mean = 0,sd = 1))
p_vect=seq(1,4,length.out = 10)
gauss_variable <- sapply(1:nbr_it, function(it) hist(rnorm(n,mean = 0,sd = 1))
gauss_variable
gauss_variable <- sapply(1:nbr_it, function(it) hist(rnorm(n,mean = 0,sd = 1)))
gauss_variable
length(gauss_variable)
gauss_variable <- sapply(1:nbr_it, function(it) rnorm(n,mean = 0,sd = 1))
gauss_variable
length(gauss_variable)
gauss_variable <- lapply(1:nbr_it, function(it) rnorm(n,mean = 0,sd = 1))
length(gauss_variable)
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) rnorm(n,mean = 0,sd = 1))
p_vect=seq(1,4,length.out = 10)
for (p in p_vect){
chi_p <- lapply(gauss_variable, function(x) sum(x^p))
}
chi_p
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p <- lapply(gauss_variable, function(x) sum(x^p))
}
chi_p
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
}
length(chi_p)
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
}
chi_p <- list()
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) rnorm(n,mean = 0,sd = 1))
p_vect=seq(1,4,length.out = 10)
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
}
length(chi_p)
length(chi_p[[1]])
length(chi_p[[2]])
length(chi_p[[3]])
length(chi_p[[4]])
paste("sum_1^n_Xsi^p","n=",n,"p=",p,"nbr_it",nbr_it,sep="_")
hist(chi_p[[i]],main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"))
chi_p[[i]]
unlist(chi_p[[i]])
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"))
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) rnorm(n,mean = 0,sd = 1))
p_vect=seq(1,4,length.out = 10)
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
}
length(p_vect)
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
i=1
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
i = 1
i = 2
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
chi_p[[i]]
gauss_variable
gauss_variable^p
4^p
gauss_variable^2
gauss_variable
gauss_variable[[1]]^2
gauss_variable[[1]]
gauss_variable[[1]][99]^2
gauss_variable[[1]][100]^2
gauss_variable[[1]]^(1/2)
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))
p_vect=seq(1,4,length.out = 10)
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
seq(50,1000,by=10)
hist(unlist(chi_p[[i]]),breaks = seq(50,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(50,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",p,"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",round(p,3),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",round(p,3),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),main = paste("sum_1^n_Xsi^p_with","n=",n,"p=",round(p,2),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))
p_vect=seq(1,4,length.out = 10)
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),main = paste("sum_1^n_|Xsi|^p_with","n=",n,"p=",round(p,2),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),ylim = c(0,500),main = paste("sum_1^n_|Xsi|^p_with","n=",n,"p=",round(p,2),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
print(p)
}
rm(list=objects())
n=100
nbr_it = 1000
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))
gauss_variable
p_vect=seq(1,4,length.out = 10)   # les differents p
p_vect
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))   # les gaussiennes
chi_p <- list()
gauss_variable[[1]]
rm(list=objects())
n=100   # le n de la somme
nbr_it = 1000    # Monte Carlo
p_vect=seq(1,4,length.out = 10)   # les differents p
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))   # abs des gaussiennes
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))    # donne un vecteur de taille 1000
# chaque element est la realisation d'un chi_p
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),ylim = c(0,500),main = paste("sum_1^n_|Xsi|^p_with","n=",n,"p=",round(p,2),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
}
rm(list=objects())
n=100   # le n de la somme
nbr_it = 1000    # Monte Carlo
p_vect=seq(1,4,length.out = 10)   # les differents p
pdf("chi_p_distribution.pdf")
gauss_variable <- lapply(1:nbr_it, function(it) abs(rnorm(n,mean = 0,sd = 1)))   # abs des gaussiennes
chi_p <- list()
for (i in 1:length(p_vect)){
p = p_vect[i]
chi_p[[i]] <- lapply(gauss_variable, function(x) sum(x^p))    # donne un vecteur de taille 1000
# chaque element est la realisation d'un chi_p
hist(unlist(chi_p[[i]]),breaks = seq(10,1000,by=10),ylim = c(0,500),main = paste("sum_1^n_|Xsi|^p_with","n=",n,"p=",round(p,2),"nbr_it",nbr_it,sep="_"),xlab="sum_chi_p")
}
dev.off()
x= c(1,2,3)
y= c(1,1,1)
x
y
z = c(x,y)
z
## script to launch simulations
## author : Perrine Lacroix
## date : March, 10 2021
## This code creates the data sets and the model collections.
## The first data sets are used to get the estimated FDR and the estimated PR functions, as well as the empirical estimations of FDR and PR
## The second data sets are used to test the FDR bounds construction with their variability.
## For each data set, the fixed design matrix is firstly built and a Gaussian noise is generated.
## Then, Y is obtained after the beta_0 construction which gives an order of relevance on the X_j.
## Lastly, the nested model collection respecting the order of relevance on the X_j is generated and characteristics of each model are computed.
rm(list=objects())
prefix = "~/Documents/GitHub/Trade_off_FDR_PR"
setwd(paste(prefix,"/data",sep =""))
# Parameters of simulation
nbr_it = 1000   # Data sets number for the empirical estimations of FDR and PR.
nbr_it_bound = 100   # Data sets number to compute the FDR bounds and to study the variability of the FDR bounds.
n = 50  # number of observations
p = 50   # number of variables
n_temps = 2*n*nbr_it   # Required total iterations number to get nbr_it train sets for the empirical estimation of FDR, with nbr_it validation sets for the empirical estimation of PR.
n_temps_bounds = n*nbr_it_bound   # Required total iterations number to get nbr_it_bound data sets for the FDR bounds and the variability studies of the FDR bounds.
sigma_2 <- 1   # Variance of the noise in the Gaussian linear regression
## parameters of the created data for the saving
config_data = paste0(paste("sigma2",sigma_2,"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
set.seed(1234)
## X matrix
data_select <- matrix(0,nrow=n,ncol=p)   # the train matrix
diag(data_select) <- rep(1,length(diag(data_select)))
data_metric <- matrix(0,nrow=n,ncol=p)  # the validation matrix
diag(data_metric) <- rep(1,length(diag(data_metric)))
colnames(data_select) <-  paste(rep("covariable",p),1:p)
rownames(data_select) <-  paste(rep("observation",n),1:n)
colnames(data_metric) <-  colnames(data_select)
rownames(data_metric) <-  rownames(data_select)
## noise
noise <- rnorm(2*nbr_it*n,0,sqrt(sigma_2))
## Saving the data sets
save(data_select,data_metric,noise,file=paste("matrix_X",config_data,sep="_"))
setwd(paste(prefix,"/data",sep =""))
load(paste("matrix_X",config_data,sep="_"))
config_data = paste0(paste("beta_true_0_20","sigma2",sigma_2,
"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
vrai_beta_matrix <- matrix(0,nrow = p,ncol =21)
colnames(vrai_beta_matrix) <- sapply(0:20, function(j) paste("size_beta_0",j,sep = "_"))
vrai_beta_matrix[1,2] <- 2*sigma_2
# vrai_beta_matrix[1,2] <- sigma_2/10    # the configuration 2 of the scenario (ii)  of the article
# vrai_beta_matrix[1,2] <- 2*sigma_2     # the configuration 3 of the scenario (ii)  of the article
for (k in 2:20){  # size of beta_0 support
index <- k+1
vrai_beta_matrix[(index-1),index] <- 2
# vrai_beta_matrix[(index-1),index] <- sigma_2/10      # the configuration 2 of the scenario (ii)  of the article
for (j in (index-2):1){
vrai_beta_matrix[j,index] <- round(runif(1,as.numeric(vrai_beta_matrix[j+1,index]+0.5),as.numeric(vrai_beta_matrix[j+1,index])+1.5),3)
# vrai_beta_matrix[j,index] <- round(runif(1,as.numeric(vrai_beta_matrix[j+1,index]+0.05),as.numeric(vrai_beta_matrix[j+1,index])+0.15),3)
# the configurations 2 and 3 of the scenario (ii)  of the article
}
}
## Y construction
Y_select_matrix <- matrix(NA,nrow = n*nbr_it, ncol = ncol(vrai_beta_matrix))  # the train sets of Y
Y_metric_matrix <- matrix(NA,nrow = n*nbr_it, ncol = ncol(vrai_beta_matrix))    # the validation sets of Y
colnames(Y_select_matrix) <- sapply(0:20, function(j) paste("size_beta_0",j,sep = "_"))
colnames(Y_metric_matrix) <- sapply(0:20, function(j) paste("size_beta_0",j,sep = "_"))
for (k in seq(1,n*nbr_it,by=n)){
Y_select_matrix[k:(k+(n-1)),] <- sapply(1:ncol(vrai_beta_matrix), function(j) data_select %*% vrai_beta_matrix[,j] + noise[k:(k+(n-1))])
Y_metric_matrix[k:(k+(n-1)),] <- sapply(1:ncol(vrai_beta_matrix), function(j) data_metric %*% vrai_beta_matrix[,j] + noise[(n*nbr_it+k):(n*nbr_it+k+(n-1))])
}
## Saving the data sets
save(Y_select_matrix,Y_metric_matrix,vrai_beta_matrix,file=paste("vector_Y",config_data,sep="_"))
# save(Y_select_matrix,Y_metric_matrix,vrai_beta_matrix,file=paste("smaller_noise_vector_Y",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# save(Y_select_matrix,Y_metric_matrix,vrai_beta_matrix,file=paste("larger_noise_closed_values_vector_Y",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
setwd(paste(prefix,"/data",sep =""))
config_data = paste0(paste("sigma2",sigma_2,
"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("matrix_X",config_data,sep="_"))
config_data = paste0(paste("beta_true_0_20","sigma2",sigma_2,"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("vector_Y",config_data,sep="_"))
# load(paste("smaller_noise_vector_Y",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# load(paste("larger_noise_closed_values_vector_Y",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
## noise
noise_bounds <- rnorm(nbr_it_bound*n,0,sqrt(sigma_2))
## Y_bounds
Y_bounds_matrix <- matrix(NA,nrow = n*nbr_it_bound, ncol = ncol(vrai_beta_matrix))
colnames(Y_bounds_matrix) <- sapply(0:20, function(j) paste("size_beta_0",j,sep = "_"))
for (k in seq(1,n*nbr_it_bound,by=n)){
Y_bounds_matrix[k:(k+(n-1)),] <- sapply(1:ncol(vrai_beta_matrix), function(j) data_select %*% vrai_beta_matrix[,j] + noise_bounds[k:(k+(n-1))])
}
save(Y_bounds_matrix,noise_bounds,file=paste("vector_Y_noise_bounds",config_data,sep="_"))
# save(Y_bounds_matrix,noise_bounds,file=paste("vector_Y_smaller_noise_noise_bounds",config_data,sep="_"))   # the configuration 2 of the scenario (ii)  of the article
# save(Y_bounds_matrix,noise_bounds,file=paste("vector_Y_larger_noise_closed_values_bounds",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
setwd(paste(prefix,"/data",sep =""))
config_data = paste0(paste("sigma2",sigma_2,
"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("matrix_X",config_data,sep="_"))
config_data = paste0(paste("beta_true_0_20","sigma2",sigma_2,"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("vector_Y",config_data,sep="_"))
# load(paste("smaller_noise_vector_Y",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# load(paste("larger_noise_closed_values_vector_Y",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
load(paste("vector_Y_noise_bounds",config_data,sep="_"))
# load(paste("vector_Y_smaller_noise_bounds",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# load(paste("vector_Y_larger_noise_closed_values_bounds",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
dimension <- 0:p
path_collection <- list()
support <- list()   # list for the supports of variable in the collection
support_num <- list()    # list for the supports of variable index in the collection
for(k in 2:(p+1)){
support[[k]] <- colnames(data_metric)[1:(k-1)]
support_num[[k]] <- 1:(k-1)
}
pb = txtProgressBar(min = 1, max = ncol(vrai_beta_matrix), initial = 1)
for (l in 1:(ncol(Y_select_matrix))){
Y_select <- Y_select_matrix[,l]
path_collection[[l]] <- list()
for (k in seq(1,n*nbr_it,by=n)){
j = which(seq(1,n*nbr_it,by=n) ==k)
set.seed(j+1234)
index <- 2:(p+1)
re_estimation <- list()
for (i in index){
re_estimation[[i]] <- lm(Y_select[k:(k+(n-1))] ~ data_select[,support_num[[i]]] -1)  # No intercept, mean square estimators onto each model
# The beta coefficients are re-estimated onto each model of the collection by the MSE minization
}
beta_new <- sapply(re_estimation, function(a) as.vector(a$coefficients))
for (i in index){
names(beta_new[[i]]) <- support[[i]]
}
beta_estimator <- matrix(0, nrow = length(support), ncol = p)
for (i in 2:length(support)){
beta_estimator[i,support_num[[i]]] <- as.numeric(beta_new[[i]])
}
LS = sapply(1:length(dimension), function(i)
(1/nrow(data_select))*sum((Y_select[k:(k+(n-1))] - data_select %*% beta_estimator[i,])^2))
# The least squared values are computed for each beta of the collection
data_frame_temp_1 <- data.frame(LS=LS,dim=dimension,complexite=lchoose(p,dimension))      # characteristics of the model collection
data_frame_temp_2 <- data.frame(beta=beta_estimator)
path_collection[[l]][[j]]=list(val1 = data_frame_temp_1, val2 = data_frame_temp_2)
}
setTxtProgressBar(pb,l)
}
save(path_collection,file=paste("path_collection",config_data,sep="_"))
# save(path_collection,file=paste("smaller_noise_path_collection",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# save(path_collection,file=paste("larger_noise_closed_values_path_collection",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
rm(list=objects())
prefix = "~/Documents/GitHub/Trade_off_FDR_PR"
# Packages loading
library(xtable)
library(ggplot2)
library(capushe)
## Loading of coded function
setwd(paste(prefix,"/source",sep =""))
source("Git_cste_mult_variation_PR_FDP.R")
source("Git_empirical_estimation.R")
source("Git_P_2r_estimation.R")
source("Git_lower_bounds.R")
source("Git_upper_bounds.R")
source("Git_lower_bound_estimated_one_dataset.R")
source("Git_upper_bound_estimated_one_dataset.R")
## Loading of the dataset
setwd(paste(prefix,"/data",sep =""))
# Parameters of simulation
nbr_it = 1000   # Data sets number for the empirical estimations of FDR and PR.
nbr_it_bound = 100   # Data sets number to compute the FDR bounds and to study the variability of the FDR bounds.
n = 50  # number of observations
p = 50   # number of variables
source("Git_empirical_estimation.R")
source("Git_empirical_estimation.R")
rm(list=objects())
prefix = "~/Documents/GitHub/Trade_off_FDR_PR"
# Packages loading
library(xtable)
library(ggplot2)
library(capushe)
## Loading of coded function
setwd(paste(prefix,"/source",sep =""))
source("Git_cste_mult_variation_PR_FDP.R")
source("Git_empirical_estimation.R")
source("Git_P_2r_estimation.R")
source("Git_lower_bounds.R")
source("Git_upper_bounds.R")
source("Git_lower_bound_estimated_one_dataset.R")
source("Git_upper_bound_estimated_one_dataset.R")
## Loading of the dataset
setwd(paste(prefix,"/data",sep =""))
# Parameters of simulation
nbr_it = 1000   # Data sets number for the empirical estimations of FDR and PR.
nbr_it_bound = 100   # Data sets number to compute the FDR bounds and to study the variability of the FDR bounds.
n = 50  # number of observations
p = 50   # number of variables
sigma_2 <- 1  # Variance of the noise in the Gaussian linear regression
cste_mult_vect <- seq(0.1,10,length.out = 20)    # The considered K constants
cste_mult_vect <- c(cste_mult_vect[which(cste_mult_vect<2)],2,cste_mult_vect[which(cste_mult_vect>2)])    # To add the constant 2 in the studied K
asympt_number <- 5000    # Number for the empirical estimation of the P_{2r} term in the FDR expression.
# Loading the generated data sets
config_data = paste0(paste("sigma2",sigma_2,"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("matrix_X",config_data,sep="_"))
config_data = paste0(paste("beta_true_0_20","sigma2",sigma_2,"p",p,"n",n,"nbr_it",nbr_it,sep="_"),".RData")
load(paste("vector_Y",config_data,sep="_"))
# load(paste("smaller_noise_vector_Y",config_data,sep="_"))    # the configuration 2 of the scenario (ii)  of the article
# load(paste("larger_noise_closed_values_vector_Y",config_data,sep="_"))    # the configuration 3 of the scenario (ii)  of the article
load(paste("path_collection",config_data,sep="_"))
#### The following line gives the PR and the FDP of the selected model for each considered K and on all the nbr_it data sets
#### PR_FDP_Hat_K is a matrix of size nbr_it x length(cste_mult_vect)
PR_FDP_hat_K <- empirical_estimation(cste_mult_vect,nbr_it,n,p,sigma_2,path_collection,Y_metric_matrix,data_select,data_metric)
setwd(paste(prefix,"/data",sep =""))
save(PR_FDP_hat_K, file = paste("PR_FDP_hat_K",config_data,sep="_"))
#####################################################################################################################
###### Empirical estimation of the P_{2r} term in the FDR expression
#####################################################################################################################
setwd(paste(prefix,"/data",sep =""))
load(paste("PR_FDP_hat_K",config_data,sep="_"))
# P_{2r} is deterministic if r is known. r varies between D_m_star+1 and q.
# We generate P_{2r} for r in [D_m_star +1,q] for all possible D_m_star (in [0,q])
# Then, P_{2r} will be used for appropriated r (according to D_m_star or D_m_hat)
list_P_2r <- P_2r_estimation(n,p,asympt_number,cste_mult_vect)
setwd(paste(prefix,"/data",sep =""))
save(list_P_2r,file=paste0(paste("estimation_of_P_2r_for_all_D_m_in_0_q","p",p,"n",n,"asympt_number",asympt_number,sep="_"),".RData"))
detail <- FALSE
list_lower_bounds <- lower_bounds(detail,true_beta_matrix,n,p,cste_mult_vect,sigma_2,path_collection,list_P_2r)
vrai_beta_matrix
true_beta_matrix <- vrai_beta_matrix
list_lower_bounds <- lower_bounds(detail,true_beta_matrix,n,p,cste_mult_vect,sigma_2,path_collection,list_P_2r)
